{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterator, Mapping, Tuple\n",
    "from rl.distribution import Categorical\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.policy import FinitePolicy, FiniteDeterministicPolicy\n",
    "\n",
    "import itertools as it\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the state mapping:\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Froggie_State(int):\n",
    "    lilypad_idx: int\n",
    "\n",
    "    def __hash__(self):\n",
    "        return super().__hash__()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Froggie_Croak(str):\n",
    "    croak: str\n",
    "\n",
    "    def __hash__(self):\n",
    "        return super().__hash__()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Froggie_StateActionTransition:\n",
    "\n",
    "    num_lilypads: int\n",
    "    reward_method: str\n",
    "\n",
    "    @property\n",
    "    def get_stateaction_map(\n",
    "        self,\n",
    "    ) -> Mapping[\n",
    "        Froggie_State, Mapping[Froggie_Croak, Categorical[Tuple[Froggie_State, float]]]\n",
    "    ]:\n",
    "        self.stateaction_map = {}\n",
    "        for init_pad in np.arange(1, self.num_lilypads):\n",
    "            for croak in {\"A\", \"B\"}:\n",
    "                self.add_stateaction(state=Froggie_State(init_pad), croak=croak)\n",
    "        return self.stateaction_map\n",
    "\n",
    "    def add_stateaction(self, state: Froggie_State, croak: str) -> None:\n",
    "        if state in self.stateaction_map.keys():\n",
    "\n",
    "            self.stateaction_map[state].update(\n",
    "                {croak: self.prob(action=croak, state=state)}\n",
    "            )\n",
    "        else:\n",
    "            self.stateaction_map[state] = {croak: self.prob(action=croak, state=state)}\n",
    "\n",
    "    def reward(self, state: Froggie_State, next_state: Froggie_State):\n",
    "        if self.reward_method == \"linear\":\n",
    "            return next_state.lilypad_idx\n",
    "        elif self.reward_method == \"comparative_linear\":\n",
    "            return next_state.lilypad_idx - state.lilypad_idx\n",
    "        elif self.reward_method == \"escape\":\n",
    "            return next_state.lilypad_idx == self.num_lilypads\n",
    "        else: raise NotImplementedError()\n",
    "\n",
    "    def prob(\n",
    "        self,\n",
    "        action: str,\n",
    "        state: Froggie_State,\n",
    "    ) -> Categorical[Tuple[Froggie_State, float]]:\n",
    "        dist = {}\n",
    "        if action == \"A\":\n",
    "            down_state = Froggie_State(state.lilypad_idx - 1)\n",
    "            dist[(down_state, self.reward(state, down_state))] = (\n",
    "                state.lilypad_idx / self.num_lilypads\n",
    "            )\n",
    "\n",
    "            up_state = Froggie_State(state.lilypad_idx + 1)\n",
    "            dist[(up_state, self.reward(state, up_state))] = (\n",
    "                self.num_lilypads - state.lilypad_idx\n",
    "            ) / self.num_lilypads\n",
    "        elif action == \"B\":\n",
    "            for pad_idx in range(0, self.num_lilypads + 1):\n",
    "                if pad_idx == state.lilypad_idx:\n",
    "                    continue\n",
    "                else:\n",
    "                    next_state = Froggie_State(pad_idx)\n",
    "                    dist[(next_state, self.reward(state, next_state))] = (\n",
    "                        1 / self.num_lilypads\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        return Categorical(dist)\n",
    "\n",
    "    # need use of reward: dictionary (state, reward) : probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Froggie_StateActionTransition(6, \"escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = FiniteMarkovDecisionProcess(f.get_stateaction_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all possible finite policies\n",
    "\n",
    "def get_all_policy_maps(f: Froggie_StateActionTransition) -> Iterator[FinitePolicy]:\n",
    "    def croak_policy_from_subset(A_subset: Tuple) -> FiniteDeterministicPolicy:\n",
    "        policy_map: Dict[Froggie_State, Froggie_Croak] = {}\n",
    "        for init_pad in np.arange(1, f.num_lilypads):\n",
    "            if init_pad in A_subset:\n",
    "                policy_map[Froggie_State(init_pad)] = Froggie_Croak(\"A\")\n",
    "            else:\n",
    "                policy_map[Froggie_State(init_pad)] = Froggie_Croak(\"B\")\n",
    "        return FiniteDeterministicPolicy(policy_map)\n",
    "\n",
    "    policy_iterator = it.chain([], [])\n",
    "    for r in np.arange(1, f.num_lilypads):\n",
    "        policy_iterator = it.chain(\n",
    "            policy_iterator, it.combinations(iterable=np.arange(1, f.num_lilypads), r=r)\n",
    "        )\n",
    "    return map(croak_policy_from_subset, policy_iterator)#; croak_policy_from_subset(A_subset=x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4615384615384616\n",
      "0.5000000000000002\n",
      "0.5000000000000002\n",
      "0.5000000000000002\n",
      "0.6153846153846154\n",
      "0.4333333333333334\n",
      "0.4615384615384616\n",
      "0.4615384615384617\n",
      "0.5833333333333334\n",
      "0.5000000000000002\n",
      "0.5000000000000001\n",
      "0.6153846153846156\n",
      "0.5000000000000002\n",
      "0.6153846153846156\n",
      "0.6666666666666666\n",
      "0.3999999999999999\n",
      "0.43333333333333335\n",
      "0.5595854922279793\n",
      "0.4615384615384616\n",
      "0.5833333333333334\n",
      "0.6373056994818653\n",
      "0.5000000000000002\n",
      "0.6153846153846156\n",
      "0.6666666666666667\n",
      "0.7142857142857143\n",
      "0.3404255319148935\n",
      "0.5312499999999999\n",
      "0.6153846153846152\n",
      "0.6875\n",
      "0.7872340425531914\n",
      "0.615384615384615\n"
     ]
    }
   ],
   "source": [
    "for policy in get_all_policy_maps(f=f):\n",
    "    mrp = mdp.apply_finite_policy(policy)\n",
    "    print(np.max(mrp.get_value_function_vec(gamma = 1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42857143, 0.47619048, 0.47619048, 0.47619048, 0.47619048,\n",
       "       0.47619048, 0.47619048, 0.47619048, 0.47619048])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrp.get_value_function_vec(gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed53eb0584307254b0c902844bcf8da812caec015d2a7bef039740197c0a4b91"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
